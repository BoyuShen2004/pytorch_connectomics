{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<a href=\"https://connectomics.readthedocs.io/en/latest/\" target=\"_blank\">\n",
        "<img width=\"768\", src=\"https://github.com/zudi-lin/pytorch_connectomics/blob/master/.github/logo_fullname.png?raw=true\"></a>\n",
        "\n",
        "\n",
        "<br>\n",
        "  <a href=\"https://colab.research.google.com/drive/1JcdQ9ZCdyQdRtUklBoNxZYC_XI0NG3Uo?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "<br>\n",
        "\n",
        "This <a href=\"https://connectomics.readthedocs.io/en/latest/index.html\">PyTorch Connectomics</a> (PyTC) notebook presents step-by-step guidance for visualizing neuron segmentation with the <a href=\"https://snemi3d.grand-challenge.org/\">SENMI3D</a> benchmark. We hope that this notebook will help you better comprehend your segmentation result.<br>Please browse the PyTC <a href=\"https://connectomics.readthedocs.io/en/latest/\">Docs</a> for details, see <a href=\"https://github.com/zudi-lin/pytorch_connectomics\">GitHub</a> or <a href=\"https://connectomics.readthedocs.io/en/latest/about/team.html\">contact us</a> for technical support, and join our <a href=\"https://pytorchconnectomics.slack.com/join/shared_invite/zt-obufj5d1-v5_NndNS5yog8vhxy4L12w#/shared-invite/email\">Slack</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "zLW3NG6MNqdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the Environment\n",
        "Install dependencies and clone GitHub <a href=\"https://github.com/zudi-lin/pytorch_connectomics\">repository</a>.\n",
        "\n",
        "**BEFORE YOU START:** Go to `Runtime -> Change runtime type` at the top left menu bar and choose `T4 GPU` instead of `CPU` for hardware accelerator. This will significantly accelerate the inference process. (Optional, but recommended)"
      ],
      "metadata": {
        "id": "W6_8RNsV_tNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neuroglancer imageio h5py\n",
        "%env PYTHONPATH="
      ],
      "metadata": {
        "id": "4vr1LNXWgpCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYAPSUPHSUkv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-latest-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU0UvYUR7rce"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "rm Miniconda3-latest-Linux-x86_64.sh\n",
        "conda create -n py3_torch python=3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAV3V4ZwU-74"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "source activate py3_torch\n",
        "conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate py3_torch\n",
        "\n",
        "### Uncheck the following lines to check PyTorch functionality. If you get \"True, 1, Tesla T4\", you're good to go ###\n",
        "# python\n",
        "# import torch\n",
        "# print(torch.cuda.is_available())\n",
        "# print(torch.cuda.device_count())\n",
        "# print(torch.cuda.get_device_name(0))\n",
        "\n",
        "git clone https://github.com/zudi-lin/pytorch_connectomics.git\n",
        "cd pytorch_connectomics\n",
        "pip install --editable ."
      ],
      "metadata": {
        "id": "7n3qhRGbKDys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "conda create -n zw python=3.7"
      ],
      "metadata": {
        "id": "YLkk8V2J_CnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "source activate zw\n",
        "git clone https://github.com/zudi-lin/waterz.git\n",
        "cd waterz\n",
        "conda install --yes --file requirements.txt -c conda-forge\n",
        "python setup.py install\n",
        "cd ..\n",
        "rm -rf waterz"
      ],
      "metadata": {
        "id": "wKXFxZGE_Ft9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Dataset and Pre-trained Model"
      ],
      "metadata": {
        "id": "a4WjNKIOsbkm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxZrgZxwd-hy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "cd pytorch_connectomics\n",
        "\n",
        "mkdir datasets\n",
        "cd datasets\n",
        "mkdir SNEMI3D\n",
        "cd SNEMI3D\n",
        "wget http://rhoana.rc.fas.harvard.edu/dataset/snemi.zip\n",
        "unzip snemi.zip\n",
        "mv image/test-input.tif ./\n",
        "rm -rf ./image\n",
        "rm -rf ./seg\n",
        "cd ..\n",
        "cd ..\n",
        "mkdir outputs\n",
        "cd outputs\n",
        "mkdir SNEMI_SwinUNETR\n",
        "cd SNEMI_SwinUNETR\n",
        "wget https://huggingface.co/pytc/Tranformer-based/resolve/main/checkpoint_150000.pth.tar?download=true\n",
        "mv checkpoint_150000.pth.tar?download=true checkpoint_150000.pth.tar\n",
        "# gdown https://drive.google.com/uc?id=1FNb_MitONBhJBZA3GyLWne1KxjRD5Veh\n",
        "cd ..\n",
        "cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Inference of Affinity Map\n",
        "***Please do the following steps before starting inference:***\n",
        "\n",
        "**1)** Please go to `pytorch_connectomics/configs/SNEMI/SNEMI-Base.yaml` and modify the following configs:\n",
        "\n",
        "> `SYSTEM.NUM_GPUS=1` (`SYSTEM.NUM_CPUS=2` if you're using CPU for inference);\n",
        "\n",
        "> `INFERENCE.SAMPLES_PER_BATCH=2` (`=1` if using CPU).\n",
        "\n",
        "**2)** (Optional) Upload your own trained model to `pytorch_connectomics/outputs/SNEMI_SwinUNETR/`.\n",
        "\n",
        "**3)** (Optional) Upload test labels to `pytorch_connectomics/datasets/SNEMI3D/` if it is available."
      ],
      "metadata": {
        "id": "W95UB9wJ798G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate py3_torch\n",
        "cd pytorch_connectomics\n",
        "\n",
        "python -u scripts/main.py \\\n",
        "--config-base configs/SNEMI/SNEMI-Base.yaml \\\n",
        "--config-file configs/SNEMI/SNEMI-Affinity-SwinUNETR.yaml --inference \\\n",
        "--checkpoint outputs/SNEMI_SwinUNETR/checkpoint_150000.pth.tar"
      ],
      "metadata": {
        "id": "18pWbLzYCZKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Segmentation"
      ],
      "metadata": {
        "id": "zKIBWzwWAlLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate zw\n",
        "cd pytorch_connectomics\n",
        "\n",
        "python\n",
        "import waterz\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "f_w = h5py.File('pred.h5', 'w')\n",
        "\n",
        "f_pred = h5py.File('./outputs/SNEMI_SwinUNETR/test/result_swinunetr.h5', 'r')\n",
        "\n",
        "# affinities is a [3, z, y, x] numpy array of uint8 if predicted by PyTC\n",
        "affinities = np.asarray(f_pred['/vol0'], dtype='float32')  # model prediction\n",
        "f_pred.close()\n",
        "f_w.create_dataset('aff', data=affinities, dtype='uint8')\n",
        "\n",
        "affinities = affinities / 255.0\n",
        "# The affinity values in the model prediction are in the interval [0, 255] and the affinity thresholds provided constraint them\n",
        "# in the interval [0.05, 0.995] hence we divide it by 255 in order to scale it.\n",
        "\n",
        "# evaluation: vi/rand\n",
        "seg_gt = None  # segmentation ground truth. If available, the prediction is evaluated against this ground truth and Rand and VI scores are produced.\n",
        "\n",
        "aff_thresholds = [0.05, 0.995]\n",
        "seg_thresholds = [0.1, 0.3, 0.6]\n",
        "\n",
        "seg = waterz.waterz(affinities,\n",
        "                    seg_thresholds,\n",
        "                    merge_function='aff50_his256',\n",
        "                    aff_threshold=aff_thresholds,\n",
        "                    gt=seg_gt)\n",
        "\n",
        "# seg will be an array of shape [3, z, y, x]. Since there are 3 segmentation thresholds, we get a result of shape\n",
        "# [z, y, x] for each threshold.\n",
        "seg = np.asarray(seg)\n",
        "\n",
        "f_w.create_dataset('seg', data=seg, dtype=seg.dtype)\n",
        "f_w.close()"
      ],
      "metadata": {
        "id": "beyx720L2fYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" src=\"https://connectomics.readthedocs.io/en/latest/_images/snemi_affinity.png\" width=\"768\">"
      ],
      "metadata": {
        "id": "3IwXUk6rv0Qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Results with <a href=\"https://github.com/google/neuroglancer\">Neuroglancer</a>\n",
        "Below is only a basic demonstration of using Neuroglancer for visualization. For more detailed instructions, please follow this <a href=\"https://connectomics.readthedocs.io/en/latest/external/neuroglancer.html#\">link</a>."
      ],
      "metadata": {
        "id": "ZRVgpynLAvwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import neuroglancer\n",
        "import numpy as np\n",
        "import imageio\n",
        "import h5py\n",
        "import os\n",
        "\n",
        "os.chdir('./pytorch_connectomics/')\n",
        "\n",
        "\n",
        "def ngLayer(data, res, oo=[0, 0, 0], tt='segmentation'):\n",
        "    return neuroglancer.LocalVolume(data,\n",
        "                                    dimensions=res,\n",
        "                                    volume_type=tt,\n",
        "                                    voxel_offset=oo)\n",
        "\n",
        "\n",
        "viewer = neuroglancer.Viewer()\n",
        "\n",
        "# SNEMI (# 3d vol dim: z,y,x)\n",
        "D0 = './datasets/SNEMI3D/'  # image\n",
        "res0 = neuroglancer.CoordinateSpace(names=['z', 'y', 'x'],\n",
        "                                    units=['nm', 'nm', 'nm'],\n",
        "                                    scales=[30, 6, 6])\n",
        "res1 = neuroglancer.CoordinateSpace(names=['c^', 'z', 'y', 'x'],\n",
        "                                    units=['', 'nm', 'nm', 'nm'],\n",
        "                                    scales=[3, 30, 6, 6])\n",
        "\n",
        "print('load im and gt segmentation')\n",
        "im = imageio.volread(D0 + 'test-input.tif')\n",
        "pred_f = h5py.File('pred.h5', 'r')\n",
        "\n",
        "aff_map = pred_f['/aff']\n",
        "seg = pred_f['/seg']\n",
        "seg_1, seg_2, seg_3 = seg[0], seg[1], seg[2]\n",
        "\n",
        "with viewer.txn() as s:\n",
        "    s.layers.append(name='im', layer=ngLayer(im, res0, tt='image'))\n",
        "    s.layers.append(name='seg_0.1', layer=ngLayer(seg_1, res0, tt='segmentation'))\n",
        "    s.layers.append(name='seg_0.3', layer=ngLayer(seg_2, res0, tt='segmentation'))\n",
        "    s.layers.append(name='seg_0.6', layer=ngLayer(seg_3, res0, tt='segmentation'))\n",
        "    s.layers.append(name='aff_map',\n",
        "                    layer=ngLayer(aff_map,\n",
        "                                  res1,\n",
        "                                  oo=[0, 0, 0, 0],\n",
        "                                  tt='image'),\n",
        "                    shader=\"\"\"\n",
        "        void main() {\n",
        "        emitRGB(vec3(toNormalized(getDataValue(0)),\n",
        "        toNormalized(getDataValue(1)),\n",
        "        toNormalized(getDataValue(2))));\n",
        "        }\n",
        "    \"\"\")\n",
        "\n",
        "viewer"
      ],
      "metadata": {
        "id": "OkXoC1wLUFHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" src=\"https://connectomics.readthedocs.io/en/latest/_images/screen_VIEWS.png\" width=\"768\">"
      ],
      "metadata": {
        "id": "FyUpRmgywZKq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}