# Lucchi mitochondria segmentation with MONAI Residual UNet
# Electron microscopy (EM) dataset
#
# This config uses MONAI's UNet with residual units - a robust baseline
# for 3D medical image segmentation. The residual connections help with
# gradient flow and improve performance over standard U-Net.

experiment_name: lucchi++_monai_unet
description: Mitochondria segmentation on Lucchi++ EM dataset using MONAI Residual UNet

# System
system:
  training:
    num_gpus: 4
    num_cpus: 8
    num_workers: 8
    batch_size: 32
  inference:
    num_gpus: 1
    num_cpus: 1
    num_workers: 1
    batch_size: 32
  seed: 42

# Model - MONAI UNet with residual units (2D)
model:
  architecture: monai_unet
  input_size: [512, 512]               # 2D input (spatial_dims auto-inferred from input_size length)
  output_size: [512, 512]
  in_channels: 1
  out_channels: 2                      # 2 channels for binary segmentation with sigmoid activation

  # UNet architecture configuration
  filters: [28, 36, 48, 64, 80]      # Standard UNet channel progression
  num_res_units: 2                     # Residual units per block
  kernel_size: 3                       # Convolution kernel size
  norm: batch                          # Batch normalization
  dropout: 0.1                         # Dropout for regularization

  # Loss configuration - Dice for overlap, BCE for pixel-wise accuracy
  loss_functions: [DiceLoss, CrossEntropyLoss]
  loss_weights: [1.0, 0.5]             # Prioritize Dice (overlap) over BCE
  loss_kwargs:
    - {include_background: false, softmax: true, to_onehot_y: true, smooth_nr: 1e-5, smooth_dr: 1e-5}  # DiceLoss with smoothing
    - {label_smoothing: 0.1}  # CrossEntropyLoss with label smoothing

# Data - Using automatic 80/20 train/val split (DeepEM-style)
data:
  # Volume configuration
  train_image: datasets/Lucchi++/train_im.h5
  train_label: datasets/Lucchi++/train_mito.h5
  train_resolution: [5, 5]        # Lucchi EM: 5nm isotropic resolution
  use_preloaded_cache: true            # Load volumes into memory for fast training

  # Patch configuration
  patch_size: [512, 512]          # Larger patches for better context
  pad_size: [32, 32]                 # Padding for valid convolutions
  pad_mode: reflect                    # Reflection padding at boundaries
  iter_num_per_epoch: 1280             # 1280 random crops per epoch
  
  # Image normalization
  image_transform:
    resize: [0.25, 0.25]                # Resize to 1/4 of original size (bilinear for images)
    normalize: "0-1"                   # Min-max normalization to [0, 1]
    clip_percentile_low: 0.0           # No clipping
    clip_percentile_high: 1.0
  
  # Augmentation
  augmentation:
    enabled: true


# Optimizer - AdamW with optimized hyperparameters
optimization:
  max_epochs: 1000
  gradient_clip_val: 1.0               # Higher clip (0.5 was too aggressive)
  accumulate_grad_batches: 1
  precision: "bf16-mixed"              # BFloat16 mixed precision
  
  optimizer:
    name: AdamW
    lr: 0.002                            # Higher initial LR (will use warmup)
    weight_decay: 0.01                   # L2 regularization
    betas: [0.9, 0.999]                  # Standard Adam betas (momentum terms)
    eps: 1.0e-8                          # Numerical stability

  # Scheduler - Cosine annealing with warmup for smooth convergence
  scheduler:
    name: CosineAnnealingLR
    warmup_epochs: 10                    # Longer warmup for stability with higher LR
    warmup_start_lr: 1.0e-4              # Start very small to avoid early instability
    min_lr: 1.0e-6                       # Minimum LR (same as warmup start for symmetry)
    t_max: 950                           # 1000 - 50 = 950 epochs for cosine decay

monitor:
  # Loss monitoring and validation frequency  
  detect_anomaly: false
  logging:
    # scalar loss
    scalar:
      loss: [train_loss_total_epoch]
      loss_every_n_steps: 10
      val_check_interval: 1.0
      benchmark: true
    
    # visualization
    images:
      enabled: true
      max_images: 8
      num_slices: 2
      log_every_n_epochs: 1                # Log every N epochs (default: 1)
      channel_mode: argmax                 # 'argmax', 'all', or 'selected'
      selected_channels: null              # Only used when channel_mode='selected'
  
  # Checkpointing
  checkpoint:
    mode: min
    save_top_k: 1
    save_last: true
    save_every_n_epochs: 10
    dirpath: outputs/lucchi++_monai_unet/checkpoints/
    # checkpoint_filename: auto-generated from monitor metric (epoch={epoch:03d}-{monitor}={value:.4f})
    use_timestamp: true       # Enable timestamped subdirectories (YYYYMMDD_HHMMSS)

  # Early stopping - More patient for better convergence
  early_stopping: 
    enabled: true
    monitor: train_loss_total_epoch
    patience: 300         # Increased patience (was 200)
    mode: min
    min_delta: 1.0e-5    # Smaller threshold for finer convergence
    check_finite: true   # Stop if monitored metric becomes NaN/inf
    threshold: 0.01      # Stop if loss gets this low (excellent convergence)
    divergence_threshold: 2.0  # Stop if loss exceeds this (training collapse)

# Inference - MONAI SlidingWindowInferer
inference:
  data:
    test_image: datasets/Lucchi++/test_im.h5
    test_label: datasets/Lucchi++/test_mito.h5
    #test_image: datasets/Lucchi++/train_im.h5
    #test_label: datasets/Lucchi++/train_mito.h5
    test_resolution: [5, 5]
    output_path: outputs/lucchi++_monai_unet/results/

  # MONAI SlidingWindowInferer parameters
  sliding_window:
    window_size: [512, 512]         # Patch size extracted from volume
    # sw_batch_size: automatically set from system.inference.batch_size (currently 32)
    overlap: 0.5                         # 50% overlap between patches
    blending: gaussian                   # Gaussian weighting for smooth blending
    sigma_scale: 0.25                   # Gaussian sigma scale (larger = smoother blending, default: 0.125)
    padding_mode: reflect                # Reflection-padding at volume boundaries

  # Test-Time Augmentation (TTA)
  test_time_augmentation:
    enabled: true        # Enable TTA for improved predictions#
    flip_axes: all                   # Flip strategy: "all" (8 flips, 8x slower), null (no aug, 1x), or custom list
    #tta_flip_axes: [[1]]                   # Flip Z-axis only (MUST use [1] for depth in BCDHW, NOT [0]!)
    # Example custom TTA: [[1], [2], [3]] for single-axis flips only (Z, Y, X) - 4x inference
    # Example custom TTA: [[1, 2], [1, 3], [2, 3]] for two-axis flips only - 4x inference
    act: softmax                     # Activation: 'sigmoid' for single-channel binary segmentation
    select_channel: [1]                    # Channel selection: null (use all channels for single-channel output)
    ensemble_mode: mean              # Ensemble strategy: 'mean' (average), 'min' (conservative), 'max' (aggressive)
    # NOTE: tta_act and tta_channel are applied even with null flip_axes (no ensemble, just activation + channel selection)
    # NOTE: If tta_channel selects specific channels, loss computation will be skipped (loss needs all class channels)


  # Postprocessing configuration (applied AFTER TTA if enabled)
  postprocessing:
    output_scale: 255                    # Scale predictions to [0, 255] for saving
    output_dtype: uint8                  # Save as uint8

  # Evaluation
  evaluation:
    enabled: true                        # Use eval mode for BatchNorm
    metrics: [jaccard]             # Metrics to compute

  # NOTE: batch_size=1 for inference
  #   During training: batch_size controls how many random patches to load
  #   During inference: batch_size=1 means process one full volume at a time
  #   sw_batch_size (above) controls how many patches are processed per GPU forward pass
