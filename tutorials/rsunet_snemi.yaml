# RSUNet configuration for SNEMI3D (aug3-long variant)
#
# Faithfully reproduces Kisuk Lee's award-winning SNEMI3D model:
# - Architecture: Residual Symmetric 3D U-Net
# - Parameters: ~1.5M (original Caffe model)
# - Training: 500K-700K iterations (~5 days on 1x Titan X Pascal)
# - Key features: Anisotropic convolutions, 2D/3D hybrid, long-range affinities
#
# Reference: Lee et al. (2017) "Superhuman Accuracy on SNEMI3D"
# Original framework: Caffe
# This config: PyTorch Lightning + RSUNet

experiment_name: rsunet_snemi_aug3_long
description: SNEMI3D neuron segmentation with RSUNet (long-range affinities, EM augmentations)

# System
system:
  training:
    num_gpus: 4
    num_cpus: 8
    num_workers: 8
    batch_size: 8              # Original: 1 patch per batch
  inference:
    num_gpus: 1
    num_cpus: 1
    num_workers: 4
    batch_size: 1
  seed: 42

# Model - RSUNet with SNEMI3D specifications
model:
  architecture: rsunet
  in_channels: 1
  out_channels: 12             # 12 affinity maps (8 long-range + 4 z-direction)

  # Feature widths: 36 → 48 → 64 → 80 per scale
  filters: [36, 48, 64, 80]

  # RSUNet-specific parameters
  rsunet_norm: batch           # Batch normalization (as in original)
  rsunet_activation: elu       # ELU activation (as in original)
  rsunet_num_groups: 8

  # Anisotropic downsampling - NO downsampling in Z
  # Original: max-pool (2×2×1) and transposed conv (2×2×1)
  rsunet_down_factors:
    - [1, 2, 2]                # Level 1: preserve Z resolution
    - [1, 2, 2]                # Level 2
    - [1, 2, 2]                # Level 3

  # 2D/3D hybrid convolutions
  # Original: 3×3×1 at finest scale, then 3×3×3 at coarser scales
  rsunet_depth_2d: 1           # First layer uses 2D convolutions
  rsunet_kernel_2d: [1, 3, 3]  # 2D kernel: 3×3×1

  # Deep supervision disabled (original doesn't use it)
  deep_supervision: false

  # Loss configuration
  # Original: Binomial cross-entropy with class rebalancing
  loss_functions: [WeightedBCEWithLogitsLoss]
  loss_weights: [1.0]
  loss_kwargs:
    - pos_weight: 10.0         # Class rebalancing (adjust based on dataset statistics)

  # Note: Long-range affinity maps (8 of 12 outputs) used only during training
  # Inference uses only nearest-neighbor affinities (4 outputs)

# Data
data:
  # SNEMI3D dataset paths
  train_image: datasets/SNEMI/train-input.tif
  train_label: datasets/SNEMI/train-labels.tif

  # Training patch size: 16 × 160 × 160 voxels (Z, Y, X) - anisotropic
  # Note: Changed Z from 18 to 16 (cleanly divisible by 2^n) to avoid rounding issues
  patch_size: [16, 160, 160]
  pad_size: [0, 0, 0]              # No padding (same convolutions)
  iter_num_per_epoch: 1280         # 700K iterations (upper bound)
  use_preloaded_cache: true

  # Image normalization
  image_transform:
    normalize: "0-1"           # Min-max normalization
    clip_percentile_low: 0.0
    clip_percentile_high: 1.0

  # Multi-channel label transformation
  # Transforms instance segmentation labels into multiple output channels
  label_transform:
    erosion: 1                 # Border erosion (seg_widen_border with 3×3×1 kernel)
                               # Marks boundary voxels as background (Kisuk Lee's preprocessing)

    # Affinity map generation (for long-range connectivity)
    # Offsets in (z, y, x) format - SNEMI3D specification
    targets:
      - name: affinity
        kwargs:
          offsets:
            # Short-range affinities
            - "0-0-1"              # x-direction, distance 1
            - "0-1-0"              # y-direction, distance 1
            - "1-0-0"              # z-direction, distance 1
            - "2-0-0"              # z-direction, distance 2
            - "3-0-0"              # z-direction, distance 3
            - "4-0-0"              # z-direction, distance 4
            # Long-range affinities (exponential spacing: 3, 9, 27)
            - "0-0-3"              # x-direction, distance 3
            - "0-0-9"              # x-direction, distance 9
            - "0-0-27"             # x-direction, distance 27
            - "0-3-0"              # y-direction, distance 3
            - "0-9-0"              # y-direction, distance 9
            - "0-27-0"             # y-direction, distance 27
        # Total: 12 affinity channels (6 short + 6 long)

  # Augmentation
  augmentation:
    enabled: true

    # Standard augmentations
    flip:
      enabled: true
      prob: 0.5
      spatial_axis: [0, 1, 2]  # Flip x/y/z

    rotate:
      enabled: true
      prob: 0.5
      max_angle: 90.0          # 90° rotations

    elastic:
      enabled: true
      prob: 0.7
      sigma_range: [4.0, 8.0]
      magnitude_range: [8.0, 16.0]

    intensity:
      enabled: true
      gaussian_noise_prob: 0.3
      gaussian_noise_std: 0.05
      shift_intensity_prob: 0.7
      shift_intensity_offset: 0.2
      contrast_prob: 0.7
      contrast_range: [0.5, 1.5]

    # EM-specific augmentations
    misalignment:
      enabled: true
      prob: 0.5
      displacement: 17         # 0-17 pixels (original spec)
      rotate_ratio: 0.5        # Mix of slip-type and translation-type

    missing_section:
      enabled: true
      prob: 0.3
      num_sections: 5          # Max 5 slices

    motion_blur:
      enabled: true
      prob: 0.3
      sections: 2              # Number of sections to blur
      kernel_size: 11          # Kernel size

    cut_noise:
      enabled: false

    cut_blur:
      enabled: false

    missing_parts:
      enabled: false

# Optimization
# Original: Adam with α=0.01, β₁=0.9, β₂=0.999, ε=0.01
optimization:
  max_epochs: 500             # ~700K iterations = many epochs
  gradient_clip_val: 0.0       # No gradient clipping in original
  accumulate_grad_batches: 1
  precision: "bf16-mixed"              # BFloat16 mixed precision

  # Performance
  deterministic: false
  benchmark: true

  optimizer:
    name: Adam                 # Adam (not AdamW)
    lr: 0.01                   # α = 0.01 (original)
    betas: [0.9, 0.999]        # β₁=0.9, β₂=0.999
    eps: 0.01                  # ε = 0.01 (original, unusually high)
    weight_decay: 0.0          # No weight decay in original

  # Learning rate scheduler
  # Original: halve α when validation loss plateaus, ≤4 times
  scheduler:
    name: ReduceLROnPlateau
    mode: min
    factor: 0.5                # Halve learning rate
    patience: 10000            # Check every N iterations
    min_lr: 0.0000625          # 0.01 / (2^4) = min LR after 4 halvings
    threshold: 0.0001
    cooldown: 0
    monitor: train_loss_total_epoch  # Monitor validation loss


# Monitoring
monitor:
  detect_anomaly: false

  logging:
    scalar:
      loss: [train_loss_total_epoch]
      loss_every_n_steps: 10
      val_check_interval: 1.0
      benchmark: true

    images:
      enabled: true
      max_images: 8            # Increased for multi-channel visualization
      num_slices: 8
      log_every_n_epochs: 1
      channel_mode: all     # 'argmax', 'all', or 'selected'
      selected_channels: null  # Only used when channel_mode='selected'

  checkpoint:
    monitor: val/loss
    mode: min
    save_top_k: 3
    save_last: true
    save_every_n_epochs: 10    # Save frequently (long training)
    dirpath: outputs/rsunet_snemi_aug3_long/checkpoints/
    checkpoint_filename: epoch={epoch:03d}-step={step:07d}-val_loss={val/loss:.4f}
    use_timestamp: true

  early_stopping:
    enabled: false             # Train for full duration

# Inference
inference:
  data:
    test_image: datasets/SNEMI/train-input.tif
    test_label: datasets/SNEMI/train-labels.tif
    test_resolution: [30, 6, 6]
    output_path: outputs/rsunet_snemi_aug3_long/results/

  # MONAI SlidingWindowInferer parameters
  sliding_window:
    window_size: [16, 180, 180]  # Patch size extracted from volume
    sw_batch_size: 4             # Number of patches processed simultaneously
    overlap: 0.5                 # 50% overlap between patches
    blending: gaussian           # Gaussian weighting for smooth blending
    sigma_scale: 0.25            # Gaussian sigma scale
    padding_mode: reflect        # Reflection-padding at volume boundaries

  # Test-Time Augmentation (TTA)
  test_time_augmentation:
    enabled: true
    flip_axes: null              # Flip strategy: "all" (8 flips), null (no aug), or custom list
    act: softmax                 # Activation: 'softmax', 'sigmoid', null
    select_channel: [1]          # Channel selection: [1] (foreground only), null (all)
    ensemble_mode: mean          # Ensemble strategy: 'mean', 'min', 'max'

  # Postprocessing
  postprocessing:
    intensity_scale: 255
    intensity_dtype: uint8

  # Evaluation
  evaluation:
    enabled: false               # Use eval mode for BatchNorm
    metrics: [adapted_rand]      # Metrics to compute


# Notes on reproducing the original model:
#
# 1. Long-range affinities:
#    - Output 12 affinity maps:
#      * x/y directions: distances 1, 3, 9, 27 voxels (4 maps each = 8 total)
#      * z direction: distances 1, 2, 3, 4 voxels (4 maps)
#    - Long-range maps (8 of 12) used ONLY during training
#    - Inference uses only nearest-neighbor (4 maps)
#
# 2. Class rebalancing:
#    - Original uses weighted BCE to handle class imbalance
#    - PyTC: use pos_weight parameter in BCEWithLogitsLoss
#    - Calculate from training data: pos_weight = neg_samples / pos_samples
#
# 3. Initialization:
#    - Original: He et al. (2015) method
#    - PyTC RSUNet: already uses Kaiming (He) initialization
#
# 4. Training duration:
#    - Original: ~5 days on 1x Titan X Pascal
#    - Modern GPUs (V100/A100): ~2-3 days expected
#    - 500K-700K iterations with batch_size=1
