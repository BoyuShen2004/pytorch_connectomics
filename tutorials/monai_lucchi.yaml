# Lucchi mitochondria segmentation with MONAI Residual UNet
# Electron microscopy (EM) dataset
#
# This config uses MONAI's UNet with residual units - a robust baseline
# for 3D medical image segmentation. The residual connections help with
# gradient flow and improve performance over standard U-Net.

experiment_name: lucchi_monai_unet
description: Mitochondria segmentation on Lucchi EM dataset using MONAI Residual UNet

# System
system:
  num_gpus: 4
  num_cpus: 8
  seed: 42

# Model - MONAI UNet with residual units
model:
  architecture: monai_unet
  input_size: [112, 112, 112]
  output_size: [112, 112, 112]
  in_channels: 1
  out_channels: 2                      # 2 channels for binary segmentation (bg + fg)

  # UNet architecture configuration
  filters: [16, 32, 64, 128, 256]      # Standard UNet channel progression
  num_res_units: 2                     # Residual units per block
  kernel_size: 3                       # Convolution kernel size
  norm: batch                          # Batch normalization
  dropout: 0.1                         # Dropout for regularization

  # Loss configuration
  loss_functions: [DiceLoss, CrossEntropyLoss]
  loss_weights: [1.0, 1.0]
  loss_kwargs:
    - {include_background: false, softmax: true, to_onehot_y: true}  # DiceLoss
    - {}                                                               # CrossEntropyLoss

# Data - Using automatic 80/20 train/val split (DeepEM-style)
data:
  # Single volume - will be automatically split into train/val
  train_image: datasets/Lucchi/img/train_im.tif
  train_label: datasets/Lucchi/label/train_label.tif

  # Patch configuration
  patch_size: [112, 112, 112]          # Larger patches for better context
  pad_size: [16, 16, 16]               # Padding for valid convolutions
  stride: [16, 16, 16]                 # Sampling stride (z, y, x) for auto iter_num

  # Data loading
  batch_size: 32
  num_workers: 8

  # Image normalization
  image_transform:
    normalize: "0-1"                   # Min-max normalization to [0, 1]
    clip_percentile_low: 0.0           # No clipping
    clip_percentile_high: 1.0

  # Label transformation (for binary segmentation)
  label_transform:
    normalize: true                    # Convert labels to binary {0,1}

  # Sampling
  iter_num: 1280                       # 1280 random crops per epoch
  use_preloaded_cache: true            # Load volumes into memory for fast training
  split_enabled: false

# Augmentation
augmentation:
  enabled: true

# Visualization - TensorBoard visualization
visualization:
  enabled: true
  max_images: 8
  num_slices: 2
  log_every_n_steps: -1                # Log at epoch end

# Optimizer - AdamW with reduced LR for stability
optimizer:
  name: AdamW
  lr: 0.0001
  weight_decay: 0.01

# Scheduler - Cosine annealing with warmup
scheduler:
  name: CosineAnnealingLR
  warmup_epochs: 10
  warmup_start_lr: 0.0001
  min_lr: 0.00001
  t_max: 990                           # 1000 - 10 = 990 epochs

# Training
training:
  max_epochs: 1000
  gradient_clip_val: 0.5
  accumulate_grad_batches: 1
  precision: "bf16-mixed"              # BFloat16 mixed precision

  # Validation frequency
  val_check_interval: 1.0
  log_every_n_steps: 10
  benchmark: true

# Checkpoint
checkpoint:
  monitor: train_loss_total_epoch
  dirpath: outputs/lucchi_monai_unet/checkpoints/
  filename: epoch={epoch:03d}-loss={train_loss_total_epoch:.4f}

# Early stopping
early_stopping:
  monitor: train_loss_total_epoch
  patience: 200
  mode: min
  min_delta: 0.0001

# Inference
inference:
  test_image: datasets/Lucchi/img/test_im.tif
  test_label: datasets/Lucchi/label/test_label.tif
  output_path: outputs/lucchi_monai_unet/results/
  metrics: [jaccard]

  # Blending configuration for patch-based inference
  blending: gaussian                    # 'gaussian' or 'bump'
  do_eval: true                        # Use eval mode for BatchNorm
  output_scale: [1.0, 1.0, 1.0]        # Output scaling factor

  # Inference-specific overrides
  num_gpus: 1
  num_cpus: 1
  batch_size: 4                        # Smaller batch for inference
  num_workers: 1

  stride: [56, 56, 56]                 # Stride for overlapping patches (50% overlap)
  overlap: 0.5
